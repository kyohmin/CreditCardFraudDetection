{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dataset X: Temperature in Fahrenheit, Y: Sales in USD\n",
        "X = [39, 40, 41, 42, 43, 43, 44, 44, 45, 45, 45, 46, 46, 47, 48, 48, 48, 48, 48, 48, 49, 49, 50, 50, 50, 50, 50, 51, 51, 52, 52, 52, 52, 52, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 56, 56, 57, 57, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 88, 88, 88, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 92, 92, 92, 92, 93, 93, 94, 94, 95, 95, 95, 95, 96, 96, 96, 97, 98, 99, 99, 99, 101, 101]\n",
        "Y = [13.17, 11.88, 18.82, 18.65, 17.02, 15.88, 19.07, 19.57, 21.62, 22.34, 19.23, 21.25, 19.81, 22.12, 24.22, 24.68, 23.78, 26.41, 25.01, 22.29, 27.81, 23.54, 22.89, 25.68, 27.29, 27.64, 27.31, 21.93, 32.18, 30.67, 28.05, 28.82, 27.87, 29.39, 32.6, 31.62, 25.71, 28.48, 30.09, 33.58, 29.75, 31.94, 33.71, 28.37, 27.41, 27.99, 30.37, 27.68, 29.53, 33.91, 34.19, 33.22, 34.47, 30.89, 35.8, 33.44, 36.79, 31.56, 35.13, 36.11, 32.39, 38.18, 29.69, 38.47, 37.74, 36.71, 32.29, 37.5, 35.33, 35.06, 36.25, 40.25, 39.69, 40.95, 37.96, 38.1, 38.21, 37.3, 39.53, 37.42, 39.42, 38.16, 37.66, 39.04, 41.44, 40.19, 37.93, 50.17, 44.15, 41.58, 40.59, 39.17, 40.57, 40.28, 41.21, 44.85, 40.94, 40.14, 38.57, 44.07, 44.1, 47.36, 45.38, 41.09, 43.78, 42.72, 42.1, 43.28, 44.31, 42.71, 43.03, 42.16, 46.74, 47.68, 44.48, 47.52, 44.98, 45.07, 45.42, 47.36, 48.26, 51.75, 45.05, 40.65, 48.65, 45.26, 46.04, 44.85, 42.94, 50.62, 45.65, 49.37, 45.89, 50.74, 47.17, 49.6, 41.68, 46.9, 47.35, 47.73, 43.73, 47.47, 51.38, 41.74, 49.88, 47.78, 42.5, 48.77, 49.46, 50.87, 49.12, 49.95, 50.31, 49.32, 52.67, 52.05, 48.82, 53.33, 54.59, 53.77, 49.6, 52.17, 46.74, 53.04, 49.34, 55.04, 57.18, 51.26, 53.78, 51.55, 50.01, 53.59, 52.47, 48.96, 53.57, 50.79, 52.13, 52.42, 54.67, 51.82, 53.21, 54.4, 55.01, 54.08, 53.97, 55.28, 54.36, 53.62, 50.65, 55.52, 58.61, 50.64, 54.28, 53.95, 53.44, 57.1, 54.26, 55.34, 53.71, 57.84, 55.91, 58.62, 58.85, 52.84, 56.59, 59.43, 59.69, 53.83, 59.41, 53.17, 53.48, 59.94, 60.31, 60.33, 53.82, 53.07, 59.48, 54.1, 56.33, 59.87, 60.75, 56.43, 60.86, 55.07, 58.39, 58.72, 57.52, 56.33, 57.47, 58.13, 60.46, 60.33, 60.89, 62.58, 61.22, 59.62, 58.31, 59.12, 57.93, 57.25, 62.2, 59.7, 64.82, 57.06, 62.52, 59.93, 61.71, 59.49, 67.42, 56.34, 59.69, 57.44, 64.63, 55.47, 61.22, 62.79, 59.91, 61.59, 63.46, 64.45, 65.42, 61.82, 64.36, 58.11, 59.47, 65.86, 61.52, 62.12, 64.23, 62.36, 62.32, 64.97, 66.15, 64.02, 63.41, 61.85, 65.49, 64.39, 66.06, 64.86, 62.85, 66.57, 65.54, 62.58, 63.29, 64.38, 60.78, 65.66, 66.61, 65.12, 63.13, 63.35, 65.4, 65.41, 68.28, 64.1, 66.26, 63.63, 67.58, 68.54, 65.2, 67.93, 67.88, 69.71, 64.22, 61.82, 68.28, 62.99, 64.96, 65.99, 70.3, 64.31, 69.59, 68.35, 69.66, 71.46, 69.9, 69.19, 67.97, 64.85, 70.43, 68.48, 70.29, 65.19, 68.0, 70.64, 69.67, 74.69, 69.78, 73.16, 71.51, 73.32, 74.09, 71.12, 67.58, 77.39, 75.11, 74.8, 73.94, 75.94, 79.31, 81.81, 75.58, 78.2, 75.6, 75.04, 77.41, 79.76, 77.18, 80.94, 75.7, 78.2, 80.75, 80.97, 80.98, 80.02, 82.83, 80.95, 82.5, 84.12, 85.13, 87.08, 89.29, 81.91, 85.02]\n",
        "\n",
        "# Hypothesis (y = wx + b)\n",
        "w = tf.Variable(tf.random.normal([1]), name=\"weight\")\n",
        "b = tf.Variable(tf.random.normal([1]), name=\"bias\")\n",
        "\n",
        "def hypothesis(inputVal):\n",
        "  return w*inputVal+b\n",
        "\n",
        "# Loss Function\n",
        "def lossFn(yHypo, yActual):\n",
        "  return tf.reduce_mean(tf.square(yHypo-yActual))\n",
        "\n",
        "# Minimize loss function\n",
        "optimizer = tf.optimizers.AdamW(learning_rate=0.0001)\n",
        "\n",
        "def train():\n",
        "  with tf.GradientTape() as g:\n",
        "    predict = hypothesis(X)\n",
        "    lossValue = lossFn(predict,Y)\n",
        "\n",
        "  gradients = g.gradient(lossValue, [w,b])\n",
        "  optimizer.apply_gradients(zip(gradients,[w,b]))\n",
        "\n",
        "for i in range(100000):\n",
        "  train()\n",
        "  if i % 1000 == 0 or i < 10:\n",
        "    predict = hypothesis(X)\n",
        "    lossValue = lossFn(predict,Y)\n",
        "    print(\"step = {}, loss = {}, weight = {}, bias = {}\".format(i,lossValue,w.numpy(),b.numpy()))\n",
        "\n",
        "# Diagram\n",
        "plt.plot(X,Y,'ro', label=\"Original Data\")\n",
        "plt.plot(X,np.array(w*X+b), label=\"Fitted Line\")\n",
        "plt.legend()\n",
        "plt.title(\"Icecream Sales by Temperature\")\n",
        "plt.xlabel(\"Temperature (F)\")\n",
        "plt.ylabel(\"Sales (USD)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ez_yon1vZYE1",
        "outputId": "dac1b376-2ea5-41bd-a9a5-5793c9e6dd4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0, loss = 3013.37646484375, weight = [-0.00190513], bias = [-0.2724087]\n",
            "step = 1, loss = 3012.568115234375, weight = [-0.00180513], bias = [-0.2723086]\n",
            "step = 2, loss = 3011.760009765625, weight = [-0.00170513], bias = [-0.27220848]\n",
            "step = 3, loss = 3010.9521484375, weight = [-0.00160514], bias = [-0.27210838]\n",
            "step = 4, loss = 3010.143798828125, weight = [-0.00150514], bias = [-0.27200827]\n",
            "step = 5, loss = 3009.3359375, weight = [-0.00140514], bias = [-0.27190816]\n",
            "step = 6, loss = 3008.52880859375, weight = [-0.00130515], bias = [-0.27180806]\n",
            "step = 7, loss = 3007.720947265625, weight = [-0.00120516], bias = [-0.27170795]\n",
            "step = 8, loss = 3006.913330078125, weight = [-0.00110517], bias = [-0.27160785]\n",
            "step = 9, loss = 3006.105712890625, weight = [-0.00100518], bias = [-0.27150774]\n",
            "step = 1000, loss = 2281.194580078125, weight = [0.09507231], bias = [-0.17539097]\n",
            "step = 2000, loss = 1684.2457275390625, weight = [0.18674046], bias = [-0.08382063]\n",
            "step = 3000, loss = 1201.2235107421875, weight = [0.27413592], bias = [0.00332611]\n",
            "step = 4000, loss = 817.9317626953125, weight = [0.3577108], bias = [0.08646393]\n",
            "step = 5000, loss = 524.2739868164062, weight = [0.43732783], bias = [0.16536999]\n",
            "step = 6000, loss = 311.684814453125, weight = [0.51222783], bias = [0.23910856]\n",
            "step = 7000, loss = 171.0700225830078, weight = [0.5808636], bias = [0.3057942]\n",
            "step = 8000, loss = 90.76344299316406, weight = [0.6407], bias = [0.3620625]\n",
            "step = 9000, loss = 55.215213775634766, weight = [0.68783915], bias = [0.40215832]\n",
            "step = 10000, loss = 45.247474670410156, weight = [0.71799177], bias = [0.4176239]\n",
            "step = 11000, loss = 43.95879364013672, weight = [0.7308478], bias = [0.40157756]\n",
            "step = 12000, loss = 43.81393051147461, weight = [0.73393446], bias = [0.3567887]\n",
            "step = 13000, loss = 43.665138244628906, weight = [0.73504174], bias = [0.290327]\n",
            "step = 14000, loss = 43.481178283691406, weight = [0.7362305], bias = [0.20760784]\n",
            "step = 15000, loss = 43.276084899902344, weight = [0.7375284], bias = [0.11510195]\n",
            "step = 16000, loss = 43.06159973144531, weight = [0.7388719], bias = [0.01807067]\n",
            "step = 17000, loss = 42.8438835144043, weight = [0.7402234], bias = [-0.08072114]\n",
            "step = 18000, loss = 42.62550354003906, weight = [0.7415736], bias = [-0.18011333]\n",
            "step = 19000, loss = 42.40740966796875, weight = [0.74292034], bias = [-0.27967498]\n",
            "step = 20000, loss = 42.18989562988281, weight = [0.7442639], bias = [-0.3792568]\n",
            "step = 21000, loss = 41.97311782836914, weight = [0.7456049], bias = [-0.47880572]\n",
            "step = 22000, loss = 41.757083892822266, weight = [0.74694395], bias = [-0.57830685]\n",
            "step = 23000, loss = 41.541748046875, weight = [0.7482819], bias = [-0.6777827]\n",
            "step = 24000, loss = 41.32720947265625, weight = [0.74961853], bias = [-0.77720326]\n",
            "step = 25000, loss = 41.11334991455078, weight = [0.75095457], bias = [-0.87658966]\n",
            "step = 26000, loss = 40.90023422241211, weight = [0.75228995], bias = [-0.9759462]\n",
            "step = 27000, loss = 40.687950134277344, weight = [0.75362396], bias = [-1.075209]\n",
            "step = 28000, loss = 40.47648620605469, weight = [0.75495696], bias = [-1.1743912]\n",
            "step = 29000, loss = 40.26566696166992, weight = [0.7562898], bias = [-1.2735733]\n",
            "step = 30000, loss = 40.05556869506836, weight = [0.7576222], bias = [-1.3727174]\n",
            "step = 31000, loss = 39.846290588378906, weight = [0.75895315], bias = [-1.4717803]\n",
            "step = 32000, loss = 39.637657165527344, weight = [0.76028436], bias = [-1.5708432]\n",
            "step = 33000, loss = 39.429725646972656, weight = [0.7616149], bias = [-1.6698692]\n",
            "step = 34000, loss = 39.222618103027344, weight = [0.7629449], bias = [-1.7688129]\n",
            "step = 35000, loss = 39.01615905761719, weight = [0.76427346], bias = [-1.8677566]\n",
            "step = 36000, loss = 38.81040954589844, weight = [0.7656042], bias = [-1.9666648]\n",
            "step = 37000, loss = 38.60530090332031, weight = [0.7669318], bias = [-2.0655682]\n",
            "step = 38000, loss = 38.401145935058594, weight = [0.7682589], bias = [-2.1643233]\n",
            "step = 39000, loss = 38.1977424621582, weight = [0.7695875], bias = [-2.2630286]\n",
            "step = 40000, loss = 37.99496078491211, weight = [0.77090925], bias = [-2.361734]\n",
            "step = 41000, loss = 37.79282760620117, weight = [0.77223885], bias = [-2.4604392]\n",
            "step = 42000, loss = 37.59131622314453, weight = [0.7735653], bias = [-2.5591445]\n",
            "step = 43000, loss = 37.390464782714844, weight = [0.77489334], bias = [-2.6578498]\n",
            "step = 44000, loss = 37.19059753417969, weight = [0.7762167], bias = [-2.7563756]\n",
            "step = 45000, loss = 36.991485595703125, weight = [0.77753925], bias = [-2.8548424]\n",
            "step = 46000, loss = 36.79301071166992, weight = [0.778865], bias = [-2.9533093]\n",
            "step = 47000, loss = 36.59516525268555, weight = [0.7801864], bias = [-3.0517762]\n",
            "step = 48000, loss = 36.397979736328125, weight = [0.7815065], bias = [-3.150243]\n",
            "step = 49000, loss = 36.20140075683594, weight = [0.7828298], bias = [-3.24871]\n",
            "step = 50000, loss = 36.00579071044922, weight = [0.7841543], bias = [-3.3470101]\n",
            "step = 51000, loss = 35.81095886230469, weight = [0.78547335], bias = [-3.4452386]\n",
            "step = 52000, loss = 35.61676788330078, weight = [0.78679067], bias = [-3.543467]\n",
            "step = 53000, loss = 35.423194885253906, weight = [0.7881121], bias = [-3.6416955]\n",
            "step = 54000, loss = 35.23026657104492, weight = [0.78943086], bias = [-3.739924]\n",
            "step = 55000, loss = 35.0379638671875, weight = [0.7907524], bias = [-3.8381524]\n",
            "step = 56000, loss = 34.84660720825195, weight = [0.7920699], bias = [-3.9362304]\n",
            "step = 57000, loss = 34.65584945678711, weight = [0.793388], bias = [-4.0343037]\n",
            "step = 58000, loss = 34.46543884277344, weight = [0.7947087], bias = [-4.132532]\n",
            "step = 59000, loss = 34.27621841430664, weight = [0.7960243], bias = [-4.2304773]\n",
            "step = 60000, loss = 34.08799362182617, weight = [0.7973379], bias = [-4.328229]\n",
            "step = 61000, loss = 33.90037536621094, weight = [0.79864764], bias = [-4.4259806]\n",
            "step = 62000, loss = 33.71340560913086, weight = [0.7999632], bias = [-4.523732]\n",
            "step = 63000, loss = 33.52704620361328, weight = [0.8012777], bias = [-4.621484]\n",
            "step = 64000, loss = 33.3413200378418, weight = [0.80259436], bias = [-4.7192354]\n",
            "step = 65000, loss = 33.15621566772461, weight = [0.80391294], bias = [-4.816987]\n",
            "step = 66000, loss = 32.97174072265625, weight = [0.80521196], bias = [-4.9147387]\n",
            "step = 67000, loss = 32.78787612915039, weight = [0.8065334], bias = [-5.0124903]\n",
            "step = 68000, loss = 32.60465621948242, weight = [0.80784416], bias = [-5.110242]\n",
            "step = 69000, loss = 32.42205047607422, weight = [0.8091604], bias = [-5.2079935]\n",
            "step = 70000, loss = 32.24007797241211, weight = [0.8104769], bias = [-5.305745]\n",
            "step = 71000, loss = 32.0590705871582, weight = [0.81178606], bias = [-5.4033065]\n",
            "step = 72000, loss = 31.879226684570312, weight = [0.81309485], bias = [-5.5005813]\n",
            "step = 73000, loss = 31.699996948242188, weight = [0.8144014], bias = [-5.597856]\n",
            "step = 74000, loss = 31.521392822265625, weight = [0.8157043], bias = [-5.695131]\n",
            "step = 75000, loss = 31.34339714050293, weight = [0.81701505], bias = [-5.7924056]\n",
            "step = 76000, loss = 31.16602897644043, weight = [0.81832266], bias = [-5.8896804]\n",
            "step = 77000, loss = 30.989276885986328, weight = [0.81962836], bias = [-5.986955]\n",
            "step = 78000, loss = 30.813146591186523, weight = [0.8209348], bias = [-6.08423]\n",
            "step = 79000, loss = 30.637636184692383, weight = [0.82224244], bias = [-6.1815047]\n",
            "step = 80000, loss = 30.462739944458008, weight = [0.8235517], bias = [-6.2787795]\n",
            "step = 81000, loss = 30.288469314575195, weight = [0.82485795], bias = [-6.3760543]\n",
            "step = 82000, loss = 30.114816665649414, weight = [0.8261648], bias = [-6.473329]\n",
            "step = 83000, loss = 29.941904067993164, weight = [0.82747006], bias = [-6.570535]\n",
            "step = 84000, loss = 29.770336151123047, weight = [0.82876873], bias = [-6.667333]\n",
            "step = 85000, loss = 29.599374771118164, weight = [0.8300711], bias = [-6.764131]\n",
            "step = 86000, loss = 29.429035186767578, weight = [0.83137214], bias = [-6.860929]\n",
            "step = 87000, loss = 29.259294509887695, weight = [0.8326742], bias = [-6.957727]\n",
            "step = 88000, loss = 29.09018325805664, weight = [0.83397734], bias = [-7.054525]\n",
            "step = 89000, loss = 28.921669006347656, weight = [0.8352738], bias = [-7.151323]\n",
            "step = 90000, loss = 28.753787994384766, weight = [0.8365767], bias = [-7.248121]\n",
            "step = 91000, loss = 28.586503982543945, weight = [0.83787334], bias = [-7.3449187]\n",
            "step = 92000, loss = 28.419843673706055, weight = [0.8391778], bias = [-7.4417167]\n",
            "step = 93000, loss = 28.253782272338867, weight = [0.8404778], bias = [-7.5385146]\n",
            "step = 94000, loss = 28.088350296020508, weight = [0.8417824], bias = [-7.6353126]\n",
            "step = 95000, loss = 27.923521041870117, weight = [0.84307975], bias = [-7.7321105]\n",
            "step = 96000, loss = 27.759977340698242, weight = [0.8443739], bias = [-7.828513]\n",
            "step = 97000, loss = 27.597179412841797, weight = [0.8456688], bias = [-7.9248343]\n",
            "step = 98000, loss = 27.434988021850586, weight = [0.8469639], bias = [-8.021155]\n",
            "step = 99000, loss = 27.273408889770508, weight = [0.848259], bias = [-8.117476]\n",
            "step = 100000, loss = 27.1124324798584, weight = [0.8495509], bias = [-8.213798]\n",
            "step = 101000, loss = 26.952062606811523, weight = [0.8508465], bias = [-8.310119]\n",
            "step = 102000, loss = 26.79332160949707, weight = [0.8521325], bias = [-8.405828]\n",
            "step = 103000, loss = 26.635740280151367, weight = [0.8534139], bias = [-8.501196]\n",
            "step = 104000, loss = 26.47874641418457, weight = [0.85469437], bias = [-8.596563]\n",
            "step = 105000, loss = 26.32235336303711, weight = [0.8559756], bias = [-8.691931]\n",
            "step = 106000, loss = 26.16655921936035, weight = [0.85725826], bias = [-8.787298]\n",
            "step = 107000, loss = 26.0113525390625, weight = [0.8585384], bias = [-8.882666]\n",
            "step = 108000, loss = 25.85674476623535, weight = [0.859821], bias = [-8.978033]\n",
            "step = 109000, loss = 25.70273208618164, weight = [0.8611013], bias = [-9.0734005]\n",
            "step = 110000, loss = 25.549320220947266, weight = [0.8623822], bias = [-9.168768]\n",
            "step = 111000, loss = 25.396495819091797, weight = [0.86366755], bias = [-9.264135]\n",
            "step = 112000, loss = 25.244266510009766, weight = [0.8649455], bias = [-9.359503]\n",
            "step = 113000, loss = 25.092636108398438, weight = [0.86622953], bias = [-9.45487]\n",
            "step = 114000, loss = 24.941604614257812, weight = [0.86750776], bias = [-9.550238]\n",
            "step = 115000, loss = 24.791162490844727, weight = [0.86879164], bias = [-9.645605]\n",
            "step = 116000, loss = 24.641315460205078, weight = [0.87006974], bias = [-9.7409725]\n",
            "step = 117000, loss = 24.492067337036133, weight = [0.87135607], bias = [-9.83634]\n",
            "step = 118000, loss = 24.343412399291992, weight = [0.8726334], bias = [-9.931707]\n",
            "step = 119000, loss = 24.19535255432129, weight = [0.8739146], bias = [-10.027075]\n",
            "step = 120000, loss = 24.047897338867188, weight = [0.8751983], bias = [-10.122442]\n",
            "step = 121000, loss = 23.901020050048828, weight = [0.87647927], bias = [-10.21781]\n",
            "step = 122000, loss = 23.754745483398438, weight = [0.87776], bias = [-10.313177]\n",
            "step = 123000, loss = 23.609067916870117, weight = [0.8790426], bias = [-10.408545]\n",
            "step = 124000, loss = 23.463987350463867, weight = [0.8803231], bias = [-10.503912]\n",
            "step = 125000, loss = 23.319499969482422, weight = [0.8816057], bias = [-10.599279]\n",
            "step = 126000, loss = 23.175607681274414, weight = [0.88288647], bias = [-10.694647]\n",
            "step = 127000, loss = 23.03322982788086, weight = [0.8841621], bias = [-10.789403]\n",
            "step = 128000, loss = 22.891948699951172, weight = [0.8854276], bias = [-10.883817]\n",
            "step = 129000, loss = 22.751249313354492, weight = [0.88670164], bias = [-10.97823]\n",
            "step = 130000, loss = 22.611135482788086, weight = [0.88797265], bias = [-11.072644]\n",
            "step = 131000, loss = 22.471599578857422, weight = [0.88923633], bias = [-11.167058]\n",
            "step = 132000, loss = 22.332658767700195, weight = [0.8905061], bias = [-11.261472]\n",
            "step = 133000, loss = 22.194293975830078, weight = [0.89177626], bias = [-11.3558855]\n",
            "step = 134000, loss = 22.056514739990234, weight = [0.8930447], bias = [-11.450299]\n",
            "step = 135000, loss = 21.91931915283203, weight = [0.894312], bias = [-11.544713]\n",
            "step = 136000, loss = 21.782703399658203, weight = [0.89558136], bias = [-11.639127]\n",
            "step = 137000, loss = 21.646671295166016, weight = [0.89684904], bias = [-11.733541]\n",
            "step = 138000, loss = 21.511226654052734, weight = [0.89811844], bias = [-11.827954]\n",
            "step = 139000, loss = 21.37636375427246, weight = [0.8993872], bias = [-11.922368]\n",
            "step = 140000, loss = 21.242084503173828, weight = [0.90065616], bias = [-12.016782]\n",
            "step = 141000, loss = 21.108386993408203, weight = [0.90192443], bias = [-12.111196]\n",
            "step = 142000, loss = 20.97527503967285, weight = [0.90319425], bias = [-12.205609]\n",
            "step = 143000, loss = 20.84274673461914, weight = [0.9044622], bias = [-12.300023]\n",
            "step = 144000, loss = 20.710800170898438, weight = [0.9057312], bias = [-12.394437]\n",
            "step = 145000, loss = 20.579439163208008, weight = [0.9070006], bias = [-12.488851]\n",
            "step = 146000, loss = 20.448659896850586, weight = [0.9082686], bias = [-12.583264]\n",
            "step = 147000, loss = 20.318462371826172, weight = [0.90953386], bias = [-12.677678]\n",
            "step = 148000, loss = 20.188854217529297, weight = [0.9108049], bias = [-12.772092]\n",
            "step = 149000, loss = 20.059823989868164, weight = [0.9120743], bias = [-12.866506]\n",
            "step = 150000, loss = 19.931379318237305, weight = [0.9133434], bias = [-12.960919]\n",
            "step = 151000, loss = 19.803516387939453, weight = [0.9146089], bias = [-13.055333]\n",
            "step = 152000, loss = 19.676729202270508, weight = [0.9158779], bias = [-13.149377]\n",
            "step = 153000, loss = 19.55130958557129, weight = [0.9171337], bias = [-13.242837]\n",
            "step = 154000, loss = 19.426462173461914, weight = [0.91839045], bias = [-13.336297]\n",
            "step = 155000, loss = 19.302183151245117, weight = [0.91964746], bias = [-13.429757]\n",
            "step = 156000, loss = 19.17848014831543, weight = [0.92090076], bias = [-13.523217]\n",
            "step = 157000, loss = 19.055347442626953, weight = [0.9221559], bias = [-13.616677]\n",
            "step = 158000, loss = 18.932785034179688, weight = [0.92341363], bias = [-13.710137]\n",
            "step = 159000, loss = 18.810794830322266, weight = [0.9246696], bias = [-13.803597]\n",
            "step = 160000, loss = 18.68937873840332, weight = [0.9259252], bias = [-13.897058]\n",
            "step = 161000, loss = 18.568531036376953, weight = [0.9271797], bias = [-13.990518]\n",
            "step = 162000, loss = 18.448257446289062, weight = [0.928437], bias = [-14.083978]\n",
            "step = 163000, loss = 18.328554153442383, weight = [0.9296923], bias = [-14.177438]\n",
            "step = 164000, loss = 18.20942497253418, weight = [0.9309469], bias = [-14.270898]\n",
            "step = 165000, loss = 18.090864181518555, weight = [0.9322034], bias = [-14.364358]\n",
            "step = 166000, loss = 17.972883224487305, weight = [0.93346035], bias = [-14.457818]\n",
            "step = 167000, loss = 17.85546112060547, weight = [0.9347157], bias = [-14.551278]\n",
            "step = 168000, loss = 17.738624572753906, weight = [0.9359666], bias = [-14.644738]\n",
            "step = 169000, loss = 17.622344970703125, weight = [0.9372299], bias = [-14.738198]\n",
            "step = 170000, loss = 17.50664520263672, weight = [0.9384831], bias = [-14.831658]\n",
            "step = 171000, loss = 17.391515731811523, weight = [0.93973964], bias = [-14.925118]\n",
            "step = 172000, loss = 17.276962280273438, weight = [0.94099444], bias = [-15.018579]\n",
            "step = 173000, loss = 17.162975311279297, weight = [0.942251], bias = [-15.112039]\n",
            "step = 174000, loss = 17.049558639526367, weight = [0.94350415], bias = [-15.205499]\n",
            "step = 175000, loss = 16.936717987060547, weight = [0.94476616], bias = [-15.298959]\n",
            "step = 176000, loss = 16.82444953918457, weight = [0.9460193], bias = [-15.392419]\n",
            "step = 177000, loss = 16.712751388549805, weight = [0.9472737], bias = [-15.485879]\n",
            "step = 178000, loss = 16.602609634399414, weight = [0.94851637], bias = [-15.578502]\n",
            "step = 179000, loss = 16.493175506591797, weight = [0.94975966], bias = [-15.671008]\n",
            "step = 180000, loss = 16.384300231933594, weight = [0.9510097], bias = [-15.7635145]\n",
            "step = 181000, loss = 16.275983810424805, weight = [0.95225054], bias = [-15.856021]\n",
            "step = 182000, loss = 16.168231964111328, weight = [0.9534943], bias = [-15.948527]\n",
            "step = 183000, loss = 16.060558319091797, weight = [0.9547408], bias = [-16.041456]\n",
            "step = 184000, loss = 15.95283031463623, weight = [0.95599675], bias = [-16.134916]\n",
            "step = 185000, loss = 15.845673561096191, weight = [0.95724994], bias = [-16.228376]\n",
            "step = 186000, loss = 15.739089012145996, weight = [0.958506], bias = [-16.321836]\n",
            "step = 187000, loss = 15.633075714111328, weight = [0.9597635], bias = [-16.415297]\n",
            "step = 188000, loss = 15.527636528015137, weight = [0.9610191], bias = [-16.508757]\n",
            "step = 189000, loss = 15.422764778137207, weight = [0.96227336], bias = [-16.602217]\n",
            "step = 190000, loss = 15.31861400604248, weight = [0.963528], bias = [-16.695547]\n",
            "step = 191000, loss = 15.216999053955078, weight = [0.96475357], bias = [-16.7871]\n",
            "step = 192000, loss = 15.11593246459961, weight = [0.96599513], bias = [-16.878653]\n",
            "step = 193000, loss = 15.015412330627441, weight = [0.96722025], bias = [-16.970205]\n",
            "step = 194000, loss = 14.915443420410156, weight = [0.9684507], bias = [-17.061758]\n",
            "step = 195000, loss = 14.816023826599121, weight = [0.96968055], bias = [-17.15331]\n",
            "step = 196000, loss = 14.717151641845703, weight = [0.970913], bias = [-17.244864]\n",
            "step = 197000, loss = 14.618827819824219, weight = [0.97214395], bias = [-17.336416]\n",
            "step = 198000, loss = 14.521052360534668, weight = [0.9733745], bias = [-17.427969]\n",
            "step = 199000, loss = 14.42382526397705, weight = [0.97459775], bias = [-17.519522]\n",
            "step = 200000, loss = 14.3271484375, weight = [0.9758328], bias = [-17.611074]\n",
            "step = 201000, loss = 14.231019020080566, weight = [0.9770629], bias = [-17.702627]\n",
            "step = 202000, loss = 14.1354398727417, weight = [0.9782902], bias = [-17.79418]\n",
            "step = 203000, loss = 14.040407180786133, weight = [0.9795207], bias = [-17.885733]\n",
            "step = 204000, loss = 13.945929527282715, weight = [0.9807586], bias = [-17.977285]\n",
            "step = 205000, loss = 13.851990699768066, weight = [0.9819806], bias = [-18.068838]\n",
            "step = 206000, loss = 13.758602142333984, weight = [0.98320484], bias = [-18.16039]\n",
            "step = 207000, loss = 13.665766716003418, weight = [0.98444194], bias = [-18.251944]\n",
            "step = 208000, loss = 13.573477745056152, weight = [0.98567426], bias = [-18.343496]\n",
            "step = 209000, loss = 13.481735229492188, weight = [0.98690283], bias = [-18.43505]\n",
            "step = 210000, loss = 13.390542984008789, weight = [0.9881325], bias = [-18.526602]\n",
            "step = 211000, loss = 13.299903869628906, weight = [0.98936236], bias = [-18.618155]\n",
            "step = 212000, loss = 13.209808349609375, weight = [0.99059474], bias = [-18.709707]\n",
            "step = 213000, loss = 13.120264053344727, weight = [0.9918257], bias = [-18.80126]\n",
            "step = 214000, loss = 13.031266212463379, weight = [0.9930545], bias = [-18.892813]\n",
            "step = 215000, loss = 12.942821502685547, weight = [0.99428535], bias = [-18.984365]\n",
            "step = 216000, loss = 12.854920387268066, weight = [0.99552304], bias = [-19.075918]\n",
            "step = 217000, loss = 12.767570495605469, weight = [0.99674654], bias = [-19.16747]\n",
            "step = 218000, loss = 12.680767059326172, weight = [0.9979746], bias = [-19.259024]\n",
            "step = 219000, loss = 12.594514846801758, weight = [0.9992073], bias = [-19.350576]\n",
            "step = 220000, loss = 12.508808135986328, weight = [1.0004374], bias = [-19.44213]\n",
            "step = 221000, loss = 12.423651695251465, weight = [1.0016696], bias = [-19.533682]\n",
            "step = 222000, loss = 12.339043617248535, weight = [1.0029019], bias = [-19.625235]\n",
            "step = 223000, loss = 12.254985809326172, weight = [1.0041318], bias = [-19.716787]\n",
            "step = 224000, loss = 12.171476364135742, weight = [1.0053588], bias = [-19.80834]\n",
            "step = 225000, loss = 12.088515281677246, weight = [1.0065881], bias = [-19.899893]\n",
            "step = 226000, loss = 12.006101608276367, weight = [1.0078214], bias = [-19.991446]\n",
            "step = 227000, loss = 11.924237251281738, weight = [1.009048], bias = [-20.082998]\n",
            "step = 228000, loss = 11.842917442321777, weight = [1.0102768], bias = [-20.174551]\n",
            "step = 229000, loss = 11.762153625488281, weight = [1.011512], bias = [-20.266104]\n",
            "step = 230000, loss = 11.68193531036377, weight = [1.0127417], bias = [-20.357656]\n",
            "step = 231000, loss = 11.602266311645508, weight = [1.0139683], bias = [-20.44921]\n",
            "step = 232000, loss = 11.523141860961914, weight = [1.0152001], bias = [-20.540762]\n",
            "step = 233000, loss = 11.444571495056152, weight = [1.0164312], bias = [-20.632315]\n",
            "step = 234000, loss = 11.366547584533691, weight = [1.0176586], bias = [-20.723867]\n",
            "step = 235000, loss = 11.289070129394531, weight = [1.0188912], bias = [-20.81542]\n",
            "step = 236000, loss = 11.212143898010254, weight = [1.0201236], bias = [-20.906973]\n",
            "step = 237000, loss = 11.135766983032227, weight = [1.0213538], bias = [-20.998526]\n",
            "step = 238000, loss = 11.0599365234375, weight = [1.022586], bias = [-21.090078]\n",
            "step = 239000, loss = 10.984654426574707, weight = [1.0238098], bias = [-21.181631]\n",
            "step = 240000, loss = 10.909921646118164, weight = [1.0250434], bias = [-21.273184]\n",
            "step = 241000, loss = 10.83574104309082, weight = [1.0262737], bias = [-21.364737]\n",
            "step = 242000, loss = 10.762105941772461, weight = [1.0275031], bias = [-21.45629]\n",
            "step = 243000, loss = 10.690510749816895, weight = [1.028714], bias = [-21.545965]\n",
            "step = 244000, loss = 10.619466781616211, weight = [1.029911], bias = [-21.63561]\n",
            "step = 245000, loss = 10.548952102661133, weight = [1.031119], bias = [-21.725256]\n",
            "step = 246000, loss = 10.478961944580078, weight = [1.0323197], bias = [-21.814901]\n",
            "step = 247000, loss = 10.40949535369873, weight = [1.0335271], bias = [-21.904547]\n",
            "step = 248000, loss = 10.340557098388672, weight = [1.0347321], bias = [-21.994192]\n",
            "step = 249000, loss = 10.272144317626953, weight = [1.0359387], bias = [-22.083838]\n",
            "step = 250000, loss = 10.204259872436523, weight = [1.037145], bias = [-22.173483]\n",
            "step = 251000, loss = 10.136895179748535, weight = [1.0383456], bias = [-22.263128]\n",
            "step = 252000, loss = 10.070061683654785, weight = [1.0395542], bias = [-22.352774]\n",
            "step = 253000, loss = 10.003754615783691, weight = [1.0407555], bias = [-22.44242]\n",
            "step = 254000, loss = 9.937971115112305, weight = [1.0419592], bias = [-22.532064]\n",
            "step = 255000, loss = 9.872714042663574, weight = [1.0431637], bias = [-22.62171]\n",
            "step = 256000, loss = 9.807981491088867, weight = [1.0443654], bias = [-22.711355]\n",
            "step = 257000, loss = 9.743778228759766, weight = [1.045576], bias = [-22.801]\n",
            "step = 258000, loss = 9.680098533630371, weight = [1.0467794], bias = [-22.890646]\n",
            "step = 259000, loss = 9.616945266723633, weight = [1.0479819], bias = [-22.980291]\n",
            "step = 260000, loss = 9.554319381713867, weight = [1.0491899], bias = [-23.069937]\n",
            "step = 261000, loss = 9.492218971252441, weight = [1.0503976], bias = [-23.159582]\n",
            "step = 262000, loss = 9.430643081665039, weight = [1.0515978], bias = [-23.249228]\n",
            "step = 263000, loss = 9.369596481323242, weight = [1.0528005], bias = [-23.338873]\n",
            "step = 264000, loss = 9.309073448181152, weight = [1.0540065], bias = [-23.428518]\n",
            "step = 265000, loss = 9.249075889587402, weight = [1.0552078], bias = [-23.518164]\n",
            "step = 266000, loss = 9.189603805541992, weight = [1.0564141], bias = [-23.60781]\n",
            "step = 267000, loss = 9.130661010742188, weight = [1.0576241], bias = [-23.697454]\n",
            "step = 268000, loss = 9.07224178314209, weight = [1.0588236], bias = [-23.7871]\n",
            "step = 269000, loss = 9.014348983764648, weight = [1.0600272], bias = [-23.876745]\n",
            "step = 270000, loss = 8.95698356628418, weight = [1.0612345], bias = [-23.96639]\n",
            "step = 271000, loss = 8.900141716003418, weight = [1.0624422], bias = [-24.056036]\n",
            "step = 272000, loss = 8.843827247619629, weight = [1.0636421], bias = [-24.145681]\n",
            "step = 273000, loss = 8.78803825378418, weight = [1.0648466], bias = [-24.235327]\n",
            "step = 274000, loss = 8.732775688171387, weight = [1.0660526], bias = [-24.324972]\n",
            "step = 275000, loss = 8.67803955078125, weight = [1.0672557], bias = [-24.414618]\n",
            "step = 276000, loss = 8.62382984161377, weight = [1.0684626], bias = [-24.504263]\n",
            "step = 277000, loss = 8.570145606994629, weight = [1.0696641], bias = [-24.593908]\n",
            "step = 278000, loss = 8.516985893249512, weight = [1.0708758], bias = [-24.683554]\n",
            "step = 279000, loss = 8.46435260772705, weight = [1.0720781], bias = [-24.7732]\n",
            "step = 280000, loss = 8.412246704101562, weight = [1.0732825], bias = [-24.862844]\n",
            "step = 281000, loss = 8.360666275024414, weight = [1.0744865], bias = [-24.95249]\n",
            "step = 282000, loss = 8.309612274169922, weight = [1.0756904], bias = [-25.042135]\n",
            "step = 283000, loss = 8.25908374786377, weight = [1.0768955], bias = [-25.13178]\n",
            "step = 284000, loss = 8.209081649780273, weight = [1.0780977], bias = [-25.221426]\n",
            "step = 285000, loss = 8.159605026245117, weight = [1.0793089], bias = [-25.311071]\n",
            "step = 286000, loss = 8.110654830932617, weight = [1.0805085], bias = [-25.400717]\n",
            "step = 287000, loss = 8.06222915649414, weight = [1.0817173], bias = [-25.490362]\n",
            "step = 288000, loss = 8.01433277130127, weight = [1.0829204], bias = [-25.580008]\n",
            "step = 289000, loss = 7.966959476470947, weight = [1.0841234], bias = [-25.669653]\n",
            "step = 290000, loss = 7.920114517211914, weight = [1.085333], bias = [-25.759298]\n",
            "step = 291000, loss = 7.873793125152588, weight = [1.0865328], bias = [-25.848944]\n",
            "step = 292000, loss = 7.828000068664551, weight = [1.0877359], bias = [-25.93859]\n",
            "step = 293000, loss = 7.782731533050537, weight = [1.0889405], bias = [-26.028234]\n",
            "step = 294000, loss = 7.7379889488220215, weight = [1.0901465], bias = [-26.11788]\n",
            "step = 295000, loss = 7.693770885467529, weight = [1.0913491], bias = [-26.207525]\n",
            "step = 296000, loss = 7.65081262588501, weight = [1.0925318], bias = [-26.295658]\n",
            "step = 297000, loss = 7.608554840087891, weight = [1.0937172], bias = [-26.383396]\n",
            "step = 298000, loss = 7.566799640655518, weight = [1.0948926], bias = [-26.471134]\n",
            "step = 299000, loss = 7.525547027587891, weight = [1.0960597], bias = [-26.558872]\n",
            "step = 300000, loss = 7.484799861907959, weight = [1.0972514], bias = [-26.64661]\n",
            "step = 301000, loss = 7.444552421569824, weight = [1.0984329], bias = [-26.734348]\n",
            "step = 302000, loss = 7.404812812805176, weight = [1.0996073], bias = [-26.822086]\n",
            "step = 303000, loss = 7.36557674407959, weight = [1.1007866], bias = [-26.909824]\n",
            "step = 304000, loss = 7.326846122741699, weight = [1.1019684], bias = [-26.997562]\n",
            "step = 305000, loss = 7.2886152267456055, weight = [1.1031505], bias = [-27.0853]\n",
            "step = 306000, loss = 7.250890254974365, weight = [1.1043254], bias = [-27.173038]\n",
            "step = 307000, loss = 7.213667869567871, weight = [1.1055026], bias = [-27.260777]\n",
            "step = 308000, loss = 7.176950454711914, weight = [1.1066836], bias = [-27.348515]\n",
            "step = 309000, loss = 7.140738010406494, weight = [1.1078591], bias = [-27.436253]\n",
            "step = 310000, loss = 7.105029106140137, weight = [1.10904], bias = [-27.52399]\n",
            "step = 311000, loss = 7.069821357727051, weight = [1.1102196], bias = [-27.611729]\n",
            "step = 312000, loss = 7.035120010375977, weight = [1.1113986], bias = [-27.699467]\n",
            "step = 313000, loss = 7.000921249389648, weight = [1.1125798], bias = [-27.787205]\n",
            "step = 314000, loss = 6.967228412628174, weight = [1.1137588], bias = [-27.874943]\n",
            "step = 315000, loss = 6.934037208557129, weight = [1.1149379], bias = [-27.96268]\n",
            "step = 316000, loss = 6.901352405548096, weight = [1.1161131], bias = [-28.050419]\n",
            "step = 317000, loss = 6.869168281555176, weight = [1.1172938], bias = [-28.138157]\n",
            "step = 318000, loss = 6.837491512298584, weight = [1.1184796], bias = [-28.225895]\n",
            "step = 319000, loss = 6.80631685256958, weight = [1.1196549], bias = [-28.313633]\n",
            "step = 320000, loss = 6.775644779205322, weight = [1.1208303], bias = [-28.401371]\n",
            "step = 321000, loss = 6.745477199554443, weight = [1.1220089], bias = [-28.489109]\n",
            "step = 322000, loss = 6.71581506729126, weight = [1.1231893], bias = [-28.576847]\n",
            "step = 323000, loss = 6.686655044555664, weight = [1.1243652], bias = [-28.664585]\n",
            "step = 324000, loss = 6.658000469207764, weight = [1.1255474], bias = [-28.752323]\n",
            "step = 325000, loss = 6.629886150360107, weight = [1.1267229], bias = [-28.839943]\n",
            "step = 326000, loss = 6.602707386016846, weight = [1.1278841], bias = [-28.926182]\n",
            "step = 327000, loss = 6.5761308670043945, weight = [1.1290383], bias = [-29.012033]\n",
            "step = 328000, loss = 6.550045490264893, weight = [1.1301911], bias = [-29.097864]\n",
            "step = 329000, loss = 6.524441719055176, weight = [1.1313425], bias = [-29.183695]\n",
            "step = 330000, loss = 6.499319553375244, weight = [1.1324981], bias = [-29.269526]\n",
            "step = 331000, loss = 6.4746809005737305, weight = [1.1336514], bias = [-29.355356]\n",
            "step = 332000, loss = 6.45052433013916, weight = [1.1348002], bias = [-29.441187]\n",
            "step = 333000, loss = 6.42685079574585, weight = [1.1359559], bias = [-29.527018]\n",
            "step = 334000, loss = 6.403656959533691, weight = [1.1371092], bias = [-29.612848]\n",
            "step = 335000, loss = 6.380946159362793, weight = [1.1382633], bias = [-29.698679]\n",
            "step = 336000, loss = 6.358718395233154, weight = [1.1394181], bias = [-29.78451]\n",
            "step = 337000, loss = 6.336971759796143, weight = [1.1405711], bias = [-29.87034]\n",
            "step = 338000, loss = 6.315708160400391, weight = [1.141726], bias = [-29.956171]\n",
            "step = 339000, loss = 6.29492712020874, weight = [1.1428769], bias = [-30.042002]\n",
            "step = 340000, loss = 6.274626731872559, weight = [1.1440305], bias = [-30.127832]\n",
            "step = 341000, loss = 6.254809856414795, weight = [1.1451839], bias = [-30.213663]\n",
            "step = 342000, loss = 6.235474586486816, weight = [1.1463416], bias = [-30.299494]\n",
            "step = 343000, loss = 6.216621398925781, weight = [1.1474925], bias = [-30.385324]\n",
            "step = 344000, loss = 6.198251724243164, weight = [1.1486489], bias = [-30.471155]\n",
            "step = 345000, loss = 6.180363655090332, weight = [1.1498002], bias = [-30.556986]\n",
            "step = 346000, loss = 6.162956237792969, weight = [1.1509546], bias = [-30.642817]\n",
            "step = 347000, loss = 6.146032810211182, weight = [1.1520981], bias = [-30.728647]\n",
            "step = 348000, loss = 6.129591941833496, weight = [1.1532574], bias = [-30.814478]\n",
            "step = 349000, loss = 6.113631248474121, weight = [1.1544082], bias = [-30.900309]\n",
            "step = 350000, loss = 6.098154544830322, weight = [1.1555657], bias = [-30.98614]\n",
            "step = 351000, loss = 6.0834550857543945, weight = [1.1566951], bias = [-31.070248]\n",
            "step = 352000, loss = 6.069250106811523, weight = [1.1578257], bias = [-31.154171]\n",
            "step = 353000, loss = 6.055505752563477, weight = [1.1589557], bias = [-31.238094]\n",
            "step = 354000, loss = 6.042221546173096, weight = [1.1600789], bias = [-31.322018]\n",
            "step = 355000, loss = 6.0294013023376465, weight = [1.1612049], bias = [-31.405941]\n",
            "step = 356000, loss = 6.017062187194824, weight = [1.162331], bias = [-31.489706]\n",
            "step = 357000, loss = 6.00541877746582, weight = [1.1634356], bias = [-31.57178]\n",
            "step = 358000, loss = 5.994223594665527, weight = [1.1645381], bias = [-31.653795]\n",
            "step = 359000, loss = 5.983468532562256, weight = [1.165639], bias = [-31.735811]\n",
            "step = 360000, loss = 5.973154544830322, weight = [1.1667455], bias = [-31.817827]\n",
            "step = 361000, loss = 5.963279724121094, weight = [1.1678481], bias = [-31.899843]\n",
            "step = 362000, loss = 5.953845977783203, weight = [1.168946], bias = [-31.98186]\n",
            "step = 363000, loss = 5.944693565368652, weight = [1.1700677], bias = [-32.065357]\n",
            "step = 364000, loss = 5.9359540939331055, weight = [1.1711956], bias = [-32.14928]\n",
            "step = 365000, loss = 5.927676677703857, weight = [1.1723245], bias = [-32.233204]\n",
            "step = 366000, loss = 5.919859886169434, weight = [1.1734488], bias = [-32.317127]\n",
            "step = 367000, loss = 5.91250467300415, weight = [1.1745716], bias = [-32.40105]\n",
            "step = 368000, loss = 5.905648231506348, weight = [1.1756983], bias = [-32.484493]\n",
            "step = 369000, loss = 5.899494171142578, weight = [1.1767697], bias = [-32.564617]\n",
            "step = 370000, loss = 5.893758773803711, weight = [1.177855], bias = [-32.644726]\n",
            "step = 371000, loss = 5.888445854187012, weight = [1.1789299], bias = [-32.724834]\n",
            "step = 372000, loss = 5.883552074432373, weight = [1.1799992], bias = [-32.804943]\n",
            "step = 373000, loss = 5.879078388214111, weight = [1.1810831], bias = [-32.88505]\n",
            "step = 374000, loss = 5.875026226043701, weight = [1.1821599], bias = [-32.96516]\n",
            "step = 375000, loss = 5.871527671813965, weight = [1.1831917], bias = [-33.042084]\n",
            "step = 376000, loss = 5.868441581726074, weight = [1.1842167], bias = [-33.118378]\n",
            "step = 377000, loss = 5.865737438201904, weight = [1.1852412], bias = [-33.19467]\n",
            "step = 378000, loss = 5.863499164581299, weight = [1.1862267], bias = [-33.267845]\n",
            "step = 379000, loss = 5.861631870269775, weight = [1.1872048], bias = [-33.340286]\n",
            "step = 380000, loss = 5.860210418701172, weight = [1.1881007], bias = [-33.40729]\n",
            "step = 381000, loss = 5.859147071838379, weight = [1.1889404], bias = [-33.46975]\n",
            "step = 382000, loss = 5.8583831787109375, weight = [1.1897261], bias = [-33.528366]\n",
            "step = 383000, loss = 5.85789155960083, weight = [1.1904348], bias = [-33.580906]\n",
            "step = 384000, loss = 5.857612609863281, weight = [1.1910347], bias = [-33.62562]\n",
            "step = 385000, loss = 5.857489585876465, weight = [1.1914866], bias = [-33.65946]\n",
            "step = 386000, loss = 5.857448577880859, weight = [1.1917729], bias = [-33.68056]\n",
            "step = 387000, loss = 5.8574419021606445, weight = [1.1919057], bias = [-33.69042]\n",
            "step = 388000, loss = 5.857441425323486, weight = [1.1919569], bias = [-33.694042]\n",
            "step = 389000, loss = 5.857439994812012, weight = [1.1919798], bias = [-33.695644]\n",
            "step = 390000, loss = 5.857439994812012, weight = [1.1919867], bias = [-33.696465]\n",
            "step = 391000, loss = 5.85744047164917, weight = [1.1919957], bias = [-33.696873]\n",
            "step = 392000, loss = 5.857439041137695, weight = [1.1919942], bias = [-33.697044]\n",
            "step = 393000, loss = 5.85744047164917, weight = [1.1919965], bias = [-33.697178]\n",
            "step = 394000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697205]\n",
            "step = 395000, loss = 5.857439994812012, weight = [1.1920005], bias = [-33.69721]\n",
            "step = 396000, loss = 5.857439994812012, weight = [1.1919974], bias = [-33.69722]\n",
            "step = 397000, loss = 5.857441425323486, weight = [1.1919978], bias = [-33.697216]\n",
            "step = 398000, loss = 5.857439041137695, weight = [1.191997], bias = [-33.697224]\n",
            "step = 399000, loss = 5.857441425323486, weight = [1.1919965], bias = [-33.697224]\n",
            "step = 400000, loss = 5.85744047164917, weight = [1.1919951], bias = [-33.69722]\n",
            "step = 401000, loss = 5.85744047164917, weight = [1.191999], bias = [-33.697212]\n",
            "step = 402000, loss = 5.857439994812012, weight = [1.1919947], bias = [-33.69713]\n",
            "step = 403000, loss = 5.857439994812012, weight = [1.1919953], bias = [-33.6972]\n",
            "step = 404000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697178]\n",
            "step = 405000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.6972]\n",
            "step = 406000, loss = 5.857439041137695, weight = [1.1920002], bias = [-33.6972]\n",
            "step = 407000, loss = 5.85744047164917, weight = [1.1919932], bias = [-33.697227]\n",
            "step = 408000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 409000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 410000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.69722]\n",
            "step = 411000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.697216]\n",
            "step = 412000, loss = 5.857438564300537, weight = [1.1919935], bias = [-33.697212]\n",
            "step = 413000, loss = 5.857441425323486, weight = [1.1919966], bias = [-33.69724]\n",
            "step = 414000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697224]\n",
            "step = 415000, loss = 5.857439041137695, weight = [1.191997], bias = [-33.69721]\n",
            "step = 416000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.6972]\n",
            "step = 417000, loss = 5.857441425323486, weight = [1.1919954], bias = [-33.697193]\n",
            "step = 418000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.69722]\n",
            "step = 419000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697212]\n",
            "step = 420000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 421000, loss = 5.857439041137695, weight = [1.191997], bias = [-33.697224]\n",
            "step = 422000, loss = 5.857438564300537, weight = [1.1919959], bias = [-33.697212]\n",
            "step = 423000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.697212]\n",
            "step = 424000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.69724]\n",
            "step = 425000, loss = 5.85744047164917, weight = [1.1919981], bias = [-33.69722]\n",
            "step = 426000, loss = 5.857441425323486, weight = [1.1919953], bias = [-33.697205]\n",
            "step = 427000, loss = 5.857439041137695, weight = [1.1919969], bias = [-33.69722]\n",
            "step = 428000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697193]\n",
            "step = 429000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.697216]\n",
            "step = 430000, loss = 5.857438564300537, weight = [1.1919959], bias = [-33.697212]\n",
            "step = 431000, loss = 5.857441425323486, weight = [1.1919953], bias = [-33.697197]\n",
            "step = 432000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69723]\n",
            "step = 433000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.697227]\n",
            "step = 434000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.6972]\n",
            "step = 435000, loss = 5.857439994812012, weight = [1.1919928], bias = [-33.69724]\n",
            "step = 436000, loss = 5.857439994812012, weight = [1.1919982], bias = [-33.69722]\n",
            "step = 437000, loss = 5.857439041137695, weight = [1.1919957], bias = [-33.697216]\n",
            "step = 438000, loss = 5.85744047164917, weight = [1.1919985], bias = [-33.697224]\n",
            "step = 439000, loss = 5.857441425323486, weight = [1.1919953], bias = [-33.697193]\n",
            "step = 440000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.69722]\n",
            "step = 441000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.69722]\n",
            "step = 442000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.69721]\n",
            "step = 443000, loss = 5.857439994812012, weight = [1.1919944], bias = [-33.69723]\n",
            "step = 444000, loss = 5.857439994812012, weight = [1.191993], bias = [-33.69724]\n",
            "step = 445000, loss = 5.857439994812012, weight = [1.1919966], bias = [-33.6972]\n",
            "step = 446000, loss = 5.85744047164917, weight = [1.1919938], bias = [-33.697224]\n",
            "step = 447000, loss = 5.857439041137695, weight = [1.1919942], bias = [-33.69722]\n",
            "step = 448000, loss = 5.857439994812012, weight = [1.1919928], bias = [-33.697227]\n",
            "step = 449000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.697224]\n",
            "step = 450000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697193]\n",
            "step = 451000, loss = 5.857441425323486, weight = [1.1919949], bias = [-33.69722]\n",
            "step = 452000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.697216]\n",
            "step = 453000, loss = 5.85744047164917, weight = [1.1920013], bias = [-33.69722]\n",
            "step = 454000, loss = 5.857439041137695, weight = [1.1919969], bias = [-33.697227]\n",
            "step = 455000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697227]\n",
            "step = 456000, loss = 5.857439994812012, weight = [1.1919978], bias = [-33.69721]\n",
            "step = 457000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697212]\n",
            "step = 458000, loss = 5.857439994812012, weight = [1.1919943], bias = [-33.69721]\n",
            "step = 459000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697216]\n",
            "step = 460000, loss = 5.857441425323486, weight = [1.1920003], bias = [-33.697224]\n",
            "step = 461000, loss = 5.857441425323486, weight = [1.1919988], bias = [-33.697205]\n",
            "step = 462000, loss = 5.857439994812012, weight = [1.1919894], bias = [-33.697224]\n",
            "step = 463000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.69721]\n",
            "step = 464000, loss = 5.85744047164917, weight = [1.191997], bias = [-33.697216]\n",
            "step = 465000, loss = 5.857439994812012, weight = [1.1919987], bias = [-33.69722]\n",
            "step = 466000, loss = 5.8574419021606445, weight = [1.1919975], bias = [-33.697227]\n",
            "step = 467000, loss = 5.857439041137695, weight = [1.1920029], bias = [-33.697224]\n",
            "step = 468000, loss = 5.857441425323486, weight = [1.1919994], bias = [-33.697212]\n",
            "step = 469000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.6972]\n",
            "step = 470000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697212]\n",
            "step = 471000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.697224]\n",
            "step = 472000, loss = 5.8574419021606445, weight = [1.192006], bias = [-33.697212]\n",
            "step = 473000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 474000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.69721]\n",
            "step = 475000, loss = 5.857439994812012, weight = [1.1919967], bias = [-33.697216]\n",
            "step = 476000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.697212]\n",
            "step = 477000, loss = 5.857439994812012, weight = [1.1919968], bias = [-33.697227]\n",
            "step = 478000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697224]\n",
            "step = 479000, loss = 5.857442378997803, weight = [1.1919975], bias = [-33.69721]\n",
            "step = 480000, loss = 5.857438564300537, weight = [1.1919957], bias = [-33.6972]\n",
            "step = 481000, loss = 5.857439994812012, weight = [1.1919986], bias = [-33.697197]\n",
            "step = 482000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.69722]\n",
            "step = 483000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 484000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.697197]\n",
            "step = 485000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697224]\n",
            "step = 486000, loss = 5.857439041137695, weight = [1.1919957], bias = [-33.697216]\n",
            "step = 487000, loss = 5.857439994812012, weight = [1.1919936], bias = [-33.697212]\n",
            "step = 488000, loss = 5.857439994812012, weight = [1.1919914], bias = [-33.697243]\n",
            "step = 489000, loss = 5.857439041137695, weight = [1.191997], bias = [-33.697224]\n",
            "step = 490000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.69721]\n",
            "step = 491000, loss = 5.857439994812012, weight = [1.191997], bias = [-33.697205]\n",
            "step = 492000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697193]\n",
            "step = 493000, loss = 5.857439994812012, weight = [1.191995], bias = [-33.69722]\n",
            "step = 494000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.697212]\n",
            "step = 495000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 496000, loss = 5.85744047164917, weight = [1.1919875], bias = [-33.697235]\n",
            "step = 497000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.697212]\n",
            "step = 498000, loss = 5.857439994812012, weight = [1.1919948], bias = [-33.697212]\n",
            "step = 499000, loss = 5.857441425323486, weight = [1.1919965], bias = [-33.69724]\n",
            "step = 500000, loss = 5.857439994812012, weight = [1.1919974], bias = [-33.69722]\n",
            "step = 501000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697205]\n",
            "step = 502000, loss = 5.85744047164917, weight = [1.1920007], bias = [-33.69722]\n",
            "step = 503000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697193]\n",
            "step = 504000, loss = 5.85744047164917, weight = [1.1919949], bias = [-33.697216]\n",
            "step = 505000, loss = 5.85744047164917, weight = [1.1919949], bias = [-33.697216]\n",
            "step = 506000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 507000, loss = 5.857439994812012, weight = [1.1919944], bias = [-33.69723]\n",
            "step = 508000, loss = 5.857439994812012, weight = [1.1919924], bias = [-33.69723]\n",
            "step = 509000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.6972]\n",
            "step = 510000, loss = 5.857439994812012, weight = [1.1919935], bias = [-33.69724]\n",
            "step = 511000, loss = 5.857439994812012, weight = [1.1919991], bias = [-33.69722]\n",
            "step = 512000, loss = 5.857439994812012, weight = [1.1919924], bias = [-33.69722]\n",
            "step = 513000, loss = 5.85744047164917, weight = [1.1919972], bias = [-33.697224]\n",
            "step = 514000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697193]\n",
            "step = 515000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.69722]\n",
            "step = 516000, loss = 5.857441425323486, weight = [1.1919992], bias = [-33.697212]\n",
            "step = 517000, loss = 5.857439994812012, weight = [1.1919978], bias = [-33.69721]\n",
            "step = 518000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69723]\n",
            "step = 519000, loss = 5.857439994812012, weight = [1.1919943], bias = [-33.697235]\n",
            "step = 520000, loss = 5.857439994812012, weight = [1.1919953], bias = [-33.6972]\n",
            "step = 521000, loss = 5.857438564300537, weight = [1.1919944], bias = [-33.697224]\n",
            "step = 522000, loss = 5.857439994812012, weight = [1.1919948], bias = [-33.69722]\n",
            "step = 523000, loss = 5.857438564300537, weight = [1.1919944], bias = [-33.697224]\n",
            "step = 524000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697224]\n",
            "step = 525000, loss = 5.85744047164917, weight = [1.1919965], bias = [-33.697193]\n",
            "step = 526000, loss = 5.857439041137695, weight = [1.1919944], bias = [-33.69722]\n",
            "step = 527000, loss = 5.857439994812012, weight = [1.191995], bias = [-33.697212]\n",
            "step = 528000, loss = 5.85744047164917, weight = [1.1919895], bias = [-33.697235]\n",
            "step = 529000, loss = 5.857439041137695, weight = [1.1919963], bias = [-33.697227]\n",
            "step = 530000, loss = 5.857439041137695, weight = [1.1919957], bias = [-33.697227]\n",
            "step = 531000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.697212]\n",
            "step = 532000, loss = 5.857439994812012, weight = [1.1919942], bias = [-33.697212]\n",
            "step = 533000, loss = 5.857439994812012, weight = [1.1919943], bias = [-33.69721]\n",
            "step = 534000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 535000, loss = 5.857439994812012, weight = [1.1919991], bias = [-33.697224]\n",
            "step = 536000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.697216]\n",
            "step = 537000, loss = 5.857439994812012, weight = [1.1919906], bias = [-33.69722]\n",
            "step = 538000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.69721]\n",
            "step = 539000, loss = 5.857439994812012, weight = [1.1919968], bias = [-33.697216]\n",
            "step = 540000, loss = 5.857439994812012, weight = [1.191997], bias = [-33.69722]\n",
            "step = 541000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.69723]\n",
            "step = 542000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69723]\n",
            "step = 543000, loss = 5.85744047164917, weight = [1.1919988], bias = [-33.69721]\n",
            "step = 544000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.6972]\n",
            "step = 545000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.697216]\n",
            "step = 546000, loss = 5.857441425323486, weight = [1.191995], bias = [-33.697224]\n",
            "step = 547000, loss = 5.8574419021606445, weight = [1.1920005], bias = [-33.697216]\n",
            "step = 548000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697197]\n",
            "step = 549000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.69721]\n",
            "step = 550000, loss = 5.857439994812012, weight = [1.1919968], bias = [-33.697216]\n",
            "step = 551000, loss = 5.857439994812012, weight = [1.1919936], bias = [-33.697212]\n",
            "step = 552000, loss = 5.857439994812012, weight = [1.1919944], bias = [-33.69723]\n",
            "step = 553000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.697224]\n",
            "step = 554000, loss = 5.857442378997803, weight = [1.1919975], bias = [-33.69721]\n",
            "step = 555000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.6972]\n",
            "step = 556000, loss = 5.85744047164917, weight = [1.1919976], bias = [-33.697197]\n",
            "step = 557000, loss = 5.857439041137695, weight = [1.1919942], bias = [-33.69722]\n",
            "step = 558000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 559000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 560000, loss = 5.857439994812012, weight = [1.191998], bias = [-33.697224]\n",
            "step = 561000, loss = 5.85744047164917, weight = [1.1919949], bias = [-33.697216]\n",
            "step = 562000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.697212]\n",
            "step = 563000, loss = 5.85744047164917, weight = [1.1919901], bias = [-33.697243]\n",
            "step = 564000, loss = 5.85744047164917, weight = [1.191998], bias = [-33.69722]\n",
            "step = 565000, loss = 5.857439041137695, weight = [1.1919951], bias = [-33.69721]\n",
            "step = 566000, loss = 5.85744047164917, weight = [1.1919954], bias = [-33.69721]\n",
            "step = 567000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697193]\n",
            "step = 568000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.697216]\n",
            "step = 569000, loss = 5.857441425323486, weight = [1.1919966], bias = [-33.697212]\n",
            "step = 570000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.697197]\n",
            "step = 571000, loss = 5.85744047164917, weight = [1.1919878], bias = [-33.697235]\n",
            "step = 572000, loss = 5.85744047164917, weight = [1.1919978], bias = [-33.697212]\n",
            "step = 573000, loss = 5.85744047164917, weight = [1.191995], bias = [-33.69721]\n",
            "step = 574000, loss = 5.857439994812012, weight = [1.1919969], bias = [-33.69724]\n",
            "step = 575000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.69722]\n",
            "step = 576000, loss = 5.857439041137695, weight = [1.1919969], bias = [-33.697205]\n",
            "step = 577000, loss = 5.857439041137695, weight = [1.1919934], bias = [-33.697227]\n",
            "step = 578000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697193]\n",
            "step = 579000, loss = 5.857441425323486, weight = [1.1919994], bias = [-33.697216]\n",
            "step = 580000, loss = 5.85744047164917, weight = [1.1919944], bias = [-33.697216]\n",
            "step = 581000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697197]\n",
            "step = 582000, loss = 5.857439994812012, weight = [1.1919944], bias = [-33.69723]\n",
            "step = 583000, loss = 5.85744047164917, weight = [1.1919986], bias = [-33.697224]\n",
            "step = 584000, loss = 5.857439994812012, weight = [1.1919954], bias = [-33.6972]\n",
            "step = 585000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.69723]\n",
            "step = 586000, loss = 5.857439994812012, weight = [1.1919968], bias = [-33.69722]\n",
            "step = 587000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.697216]\n",
            "step = 588000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.697224]\n",
            "step = 589000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697193]\n",
            "step = 590000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.69722]\n",
            "step = 591000, loss = 5.85744047164917, weight = [1.1920013], bias = [-33.697212]\n",
            "step = 592000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.697212]\n",
            "step = 593000, loss = 5.85744047164917, weight = [1.1919936], bias = [-33.69723]\n",
            "step = 594000, loss = 5.857441425323486, weight = [1.1919953], bias = [-33.697235]\n",
            "step = 595000, loss = 5.85744047164917, weight = [1.1919947], bias = [-33.697205]\n",
            "step = 596000, loss = 5.857439994812012, weight = [1.1919951], bias = [-33.697224]\n",
            "step = 597000, loss = 5.857441425323486, weight = [1.1919949], bias = [-33.69722]\n",
            "step = 598000, loss = 5.85744047164917, weight = [1.1919951], bias = [-33.69722]\n",
            "step = 599000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697224]\n",
            "step = 600000, loss = 5.857439041137695, weight = [1.1919951], bias = [-33.697193]\n",
            "step = 601000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.69722]\n",
            "step = 602000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.69721]\n",
            "step = 603000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.69723]\n",
            "step = 604000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697227]\n",
            "step = 605000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697227]\n",
            "step = 606000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.697216]\n",
            "step = 607000, loss = 5.857439994812012, weight = [1.1919934], bias = [-33.697212]\n",
            "step = 608000, loss = 5.85744047164917, weight = [1.1919945], bias = [-33.69721]\n",
            "step = 609000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.697216]\n",
            "step = 610000, loss = 5.857439994812012, weight = [1.1919981], bias = [-33.697224]\n",
            "step = 611000, loss = 5.85744047164917, weight = [1.1919932], bias = [-33.69722]\n",
            "step = 612000, loss = 5.85744047164917, weight = [1.1919919], bias = [-33.697212]\n",
            "step = 613000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.69721]\n",
            "step = 614000, loss = 5.857439994812012, weight = [1.1919967], bias = [-33.697216]\n",
            "step = 615000, loss = 5.857439994812012, weight = [1.1919936], bias = [-33.69722]\n",
            "step = 616000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.69723]\n",
            "step = 617000, loss = 5.857441425323486, weight = [1.1919854], bias = [-33.697243]\n",
            "step = 618000, loss = 5.857439041137695, weight = [1.1919982], bias = [-33.69721]\n",
            "step = 619000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.6972]\n",
            "step = 620000, loss = 5.857438564300537, weight = [1.1919942], bias = [-33.697216]\n",
            "step = 621000, loss = 5.857439041137695, weight = [1.1919931], bias = [-33.697227]\n",
            "step = 622000, loss = 5.857441425323486, weight = [1.191998], bias = [-33.697216]\n",
            "step = 623000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 624000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.69721]\n",
            "step = 625000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697216]\n",
            "step = 626000, loss = 5.857438564300537, weight = [1.1919935], bias = [-33.697212]\n",
            "step = 627000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.697235]\n",
            "step = 628000, loss = 5.857441425323486, weight = [1.1919965], bias = [-33.697224]\n",
            "step = 629000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.69721]\n",
            "step = 630000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.6972]\n",
            "step = 631000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.697193]\n",
            "step = 632000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.69722]\n",
            "step = 633000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 634000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697197]\n",
            "step = 635000, loss = 5.857439041137695, weight = [1.1919976], bias = [-33.697224]\n",
            "step = 636000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.697212]\n",
            "step = 637000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697212]\n",
            "step = 638000, loss = 5.857439994812012, weight = [1.1919912], bias = [-33.697243]\n",
            "step = 639000, loss = 5.857441425323486, weight = [1.1919992], bias = [-33.69722]\n",
            "step = 640000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.69721]\n",
            "step = 641000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.697212]\n",
            "step = 642000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697193]\n",
            "step = 643000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697216]\n",
            "step = 644000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.697212]\n",
            "step = 645000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 646000, loss = 5.857441425323486, weight = [1.1919916], bias = [-33.697235]\n",
            "step = 647000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697216]\n",
            "step = 648000, loss = 5.857439994812012, weight = [1.1919953], bias = [-33.6972]\n",
            "step = 649000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.69724]\n",
            "step = 650000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.69722]\n",
            "step = 651000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.69721]\n",
            "step = 652000, loss = 5.85744047164917, weight = [1.1919905], bias = [-33.69723]\n",
            "step = 653000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697193]\n",
            "step = 654000, loss = 5.857441425323486, weight = [1.1920025], bias = [-33.697216]\n",
            "step = 655000, loss = 5.857439041137695, weight = [1.1919957], bias = [-33.697212]\n",
            "step = 656000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697197]\n",
            "step = 657000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69723]\n",
            "step = 658000, loss = 5.85744047164917, weight = [1.1920017], bias = [-33.697224]\n",
            "step = 659000, loss = 5.857439994812012, weight = [1.1919956], bias = [-33.6972]\n",
            "step = 660000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.69723]\n",
            "step = 661000, loss = 5.857439994812012, weight = [1.1919928], bias = [-33.697224]\n",
            "step = 662000, loss = 5.85744047164917, weight = [1.1920017], bias = [-33.697212]\n",
            "step = 663000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697224]\n",
            "step = 664000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697193]\n",
            "step = 665000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.69722]\n",
            "step = 666000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.69722]\n",
            "step = 667000, loss = 5.857439041137695, weight = [1.191995], bias = [-33.697216]\n",
            "step = 668000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.69723]\n",
            "step = 669000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697227]\n",
            "step = 670000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.6972]\n",
            "step = 671000, loss = 5.857441425323486, weight = [1.1919951], bias = [-33.697216]\n",
            "step = 672000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.69722]\n",
            "step = 673000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.697216]\n",
            "step = 674000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.697224]\n",
            "step = 675000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697197]\n",
            "step = 676000, loss = 5.857441425323486, weight = [1.1919976], bias = [-33.697216]\n",
            "step = 677000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.69721]\n",
            "step = 678000, loss = 5.857439994812012, weight = [1.1920085], bias = [-33.697216]\n",
            "step = 679000, loss = 5.85744047164917, weight = [1.1919947], bias = [-33.697227]\n",
            "step = 680000, loss = 5.85744047164917, weight = [1.1919965], bias = [-33.697227]\n",
            "step = 681000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.697216]\n",
            "step = 682000, loss = 5.857439994812012, weight = [1.1919954], bias = [-33.697212]\n",
            "step = 683000, loss = 5.85744047164917, weight = [1.1919949], bias = [-33.697205]\n",
            "step = 684000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.697216]\n",
            "step = 685000, loss = 5.857443332672119, weight = [1.1919975], bias = [-33.697224]\n",
            "step = 686000, loss = 5.85744047164917, weight = [1.1920016], bias = [-33.697216]\n",
            "step = 687000, loss = 5.857439041137695, weight = [1.1919931], bias = [-33.69721]\n",
            "step = 688000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.69721]\n",
            "step = 689000, loss = 5.857439041137695, weight = [1.1919962], bias = [-33.697216]\n",
            "step = 690000, loss = 5.857439994812012, weight = [1.1919903], bias = [-33.69722]\n",
            "step = 691000, loss = 5.857438564300537, weight = [1.1919942], bias = [-33.69723]\n",
            "step = 692000, loss = 5.857439994812012, weight = [1.1919882], bias = [-33.69724]\n",
            "step = 693000, loss = 5.85744047164917, weight = [1.1919984], bias = [-33.69721]\n",
            "step = 694000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.6972]\n",
            "step = 695000, loss = 5.857439041137695, weight = [1.1919976], bias = [-33.69721]\n",
            "step = 696000, loss = 5.857439041137695, weight = [1.1919922], bias = [-33.697227]\n",
            "step = 697000, loss = 5.857439994812012, weight = [1.1919969], bias = [-33.697212]\n",
            "step = 698000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697197]\n",
            "step = 699000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.69721]\n",
            "step = 700000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 701000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697212]\n",
            "step = 702000, loss = 5.85744047164917, weight = [1.1919947], bias = [-33.697235]\n",
            "step = 703000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.697224]\n",
            "step = 704000, loss = 5.85744047164917, weight = [1.1919974], bias = [-33.69721]\n",
            "step = 705000, loss = 5.857438564300537, weight = [1.1919957], bias = [-33.6972]\n",
            "step = 706000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697193]\n",
            "step = 707000, loss = 5.857439041137695, weight = [1.1919944], bias = [-33.69722]\n",
            "step = 708000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 709000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 710000, loss = 5.857439041137695, weight = [1.1919934], bias = [-33.697227]\n",
            "step = 711000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697212]\n",
            "step = 712000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697212]\n",
            "step = 713000, loss = 5.8574419021606445, weight = [1.1919929], bias = [-33.69724]\n",
            "step = 714000, loss = 5.857439994812012, weight = [1.1919999], bias = [-33.69722]\n",
            "step = 715000, loss = 5.857439994812012, weight = [1.1919972], bias = [-33.697205]\n",
            "step = 716000, loss = 5.857439994812012, weight = [1.1919969], bias = [-33.697212]\n",
            "step = 717000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697193]\n",
            "step = 718000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.697212]\n",
            "step = 719000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697212]\n",
            "step = 720000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 721000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.69723]\n",
            "step = 722000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.69722]\n",
            "step = 723000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.6972]\n",
            "step = 724000, loss = 5.857441425323486, weight = [1.1919947], bias = [-33.69724]\n",
            "step = 725000, loss = 5.857439994812012, weight = [1.1919936], bias = [-33.69722]\n",
            "step = 726000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.69721]\n",
            "step = 727000, loss = 5.8574419021606445, weight = [1.1920028], bias = [-33.697224]\n",
            "step = 728000, loss = 5.857441425323486, weight = [1.1919954], bias = [-33.697193]\n",
            "step = 729000, loss = 5.85744047164917, weight = [1.1920019], bias = [-33.697216]\n",
            "step = 730000, loss = 5.857442378997803, weight = [1.1919975], bias = [-33.69721]\n",
            "step = 731000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697197]\n",
            "step = 732000, loss = 5.85744047164917, weight = [1.1919936], bias = [-33.69723]\n",
            "step = 733000, loss = 5.857439994812012, weight = [1.1919947], bias = [-33.69723]\n",
            "step = 734000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.6972]\n",
            "step = 735000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69723]\n",
            "step = 736000, loss = 5.857439994812012, weight = [1.1919903], bias = [-33.697224]\n",
            "step = 737000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.69722]\n",
            "step = 738000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697224]\n",
            "step = 739000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697193]\n",
            "step = 740000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.69722]\n",
            "step = 741000, loss = 5.857439994812012, weight = [1.1919881], bias = [-33.697227]\n",
            "step = 742000, loss = 5.85744047164917, weight = [1.191999], bias = [-33.697216]\n",
            "step = 743000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.69723]\n",
            "step = 744000, loss = 5.857439041137695, weight = [1.1919957], bias = [-33.697227]\n",
            "step = 745000, loss = 5.85744047164917, weight = [1.1919968], bias = [-33.697205]\n",
            "step = 746000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697212]\n",
            "step = 747000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69722]\n",
            "step = 748000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.697216]\n",
            "step = 749000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.697224]\n",
            "step = 750000, loss = 5.85744047164917, weight = [1.1919974], bias = [-33.697197]\n",
            "step = 751000, loss = 5.857441425323486, weight = [1.1919994], bias = [-33.697212]\n",
            "step = 752000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.69721]\n",
            "step = 753000, loss = 5.857439994812012, weight = [1.1920062], bias = [-33.697216]\n",
            "step = 754000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.697227]\n",
            "step = 755000, loss = 5.857439994812012, weight = [1.1919985], bias = [-33.697227]\n",
            "step = 756000, loss = 5.85744047164917, weight = [1.1919993], bias = [-33.69722]\n",
            "step = 757000, loss = 5.857441425323486, weight = [1.1919992], bias = [-33.697212]\n",
            "step = 758000, loss = 5.857439994812012, weight = [1.1919956], bias = [-33.6972]\n",
            "step = 759000, loss = 5.85744047164917, weight = [1.1919966], bias = [-33.697216]\n",
            "step = 760000, loss = 5.857439994812012, weight = [1.1919979], bias = [-33.697224]\n",
            "step = 761000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697224]\n",
            "step = 762000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.697205]\n",
            "step = 763000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.69721]\n",
            "step = 764000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 765000, loss = 5.85744047164917, weight = [1.19199], bias = [-33.69722]\n",
            "step = 766000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697227]\n",
            "step = 767000, loss = 5.857441425323486, weight = [1.1919918], bias = [-33.69723]\n",
            "step = 768000, loss = 5.857439994812012, weight = [1.1919979], bias = [-33.69721]\n",
            "step = 769000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.6972]\n",
            "step = 770000, loss = 5.857441425323486, weight = [1.1920012], bias = [-33.6972]\n",
            "step = 771000, loss = 5.857439994812012, weight = [1.191992], bias = [-33.697227]\n",
            "step = 772000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697212]\n",
            "step = 773000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 774000, loss = 5.85744047164917, weight = [1.1919969], bias = [-33.69721]\n",
            "step = 775000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 776000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697212]\n",
            "step = 777000, loss = 5.857439041137695, weight = [1.1919979], bias = [-33.69723]\n",
            "step = 778000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697224]\n",
            "step = 779000, loss = 5.857439041137695, weight = [1.1919976], bias = [-33.69721]\n",
            "step = 780000, loss = 5.85744047164917, weight = [1.1919967], bias = [-33.6972]\n",
            "step = 781000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697193]\n",
            "step = 782000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.69722]\n",
            "step = 783000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 784000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697197]\n",
            "step = 785000, loss = 5.857439994812012, weight = [1.1919935], bias = [-33.697227]\n",
            "step = 786000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697212]\n",
            "step = 787000, loss = 5.857438564300537, weight = [1.1919935], bias = [-33.697212]\n",
            "step = 788000, loss = 5.85744047164917, weight = [1.1919942], bias = [-33.69724]\n",
            "step = 789000, loss = 5.85744047164917, weight = [1.1919996], bias = [-33.69722]\n",
            "step = 790000, loss = 5.857439041137695, weight = [1.1919969], bias = [-33.697205]\n",
            "step = 791000, loss = 5.85744047164917, weight = [1.1919981], bias = [-33.697212]\n",
            "step = 792000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697193]\n",
            "step = 793000, loss = 5.857439041137695, weight = [1.1919979], bias = [-33.697212]\n",
            "step = 794000, loss = 5.857438564300537, weight = [1.1919959], bias = [-33.697212]\n",
            "step = 795000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697197]\n",
            "step = 796000, loss = 5.857441425323486, weight = [1.1919941], bias = [-33.69723]\n",
            "step = 797000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.69722]\n",
            "step = 798000, loss = 5.857438564300537, weight = [1.1919957], bias = [-33.6972]\n",
            "step = 799000, loss = 5.857439994812012, weight = [1.1919928], bias = [-33.69724]\n",
            "step = 800000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.69722]\n",
            "step = 801000, loss = 5.85744047164917, weight = [1.191995], bias = [-33.69721]\n",
            "step = 802000, loss = 5.857439994812012, weight = [1.1920078], bias = [-33.69722]\n",
            "step = 803000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697193]\n",
            "step = 804000, loss = 5.8574419021606445, weight = [1.1920005], bias = [-33.697216]\n",
            "step = 805000, loss = 5.857439041137695, weight = [1.1919976], bias = [-33.69721]\n",
            "step = 806000, loss = 5.857439994812012, weight = [1.1919969], bias = [-33.697197]\n",
            "step = 807000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.69723]\n",
            "step = 808000, loss = 5.85744047164917, weight = [1.1919875], bias = [-33.697243]\n",
            "step = 809000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.6972]\n",
            "step = 810000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.69723]\n",
            "step = 811000, loss = 5.857441425323486, weight = [1.1919905], bias = [-33.697224]\n",
            "step = 812000, loss = 5.85744047164917, weight = [1.191987], bias = [-33.697227]\n",
            "step = 813000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.697224]\n",
            "step = 814000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697193]\n",
            "step = 815000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.69722]\n",
            "step = 816000, loss = 5.85744047164917, weight = [1.1919888], bias = [-33.697227]\n",
            "step = 817000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697224]\n",
            "step = 818000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.69723]\n",
            "step = 819000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697227]\n",
            "step = 820000, loss = 5.857439041137695, weight = [1.1919951], bias = [-33.697205]\n",
            "step = 821000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697212]\n",
            "step = 822000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.69722]\n",
            "step = 823000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 824000, loss = 5.857439994812012, weight = [1.1919991], bias = [-33.697224]\n",
            "step = 825000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.6972]\n",
            "step = 826000, loss = 5.85744047164917, weight = [1.1919987], bias = [-33.697216]\n",
            "step = 827000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.69721]\n",
            "step = 828000, loss = 5.85744047164917, weight = [1.1920007], bias = [-33.69722]\n",
            "step = 829000, loss = 5.85744047164917, weight = [1.1919947], bias = [-33.697227]\n",
            "step = 830000, loss = 5.857439041137695, weight = [1.1919998], bias = [-33.697227]\n",
            "step = 831000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697227]\n",
            "step = 832000, loss = 5.85744047164917, weight = [1.1920017], bias = [-33.697212]\n",
            "step = 833000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.6972]\n",
            "step = 834000, loss = 5.85744047164917, weight = [1.1919978], bias = [-33.697212]\n",
            "step = 835000, loss = 5.857439994812012, weight = [1.1919984], bias = [-33.697224]\n",
            "step = 836000, loss = 5.857439994812012, weight = [1.1919886], bias = [-33.69723]\n",
            "step = 837000, loss = 5.857441425323486, weight = [1.1919953], bias = [-33.697197]\n",
            "step = 838000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.69721]\n",
            "step = 839000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 840000, loss = 5.85744047164917, weight = [1.1919916], bias = [-33.697216]\n",
            "step = 841000, loss = 5.857439994812012, weight = [1.1919979], bias = [-33.697224]\n",
            "step = 842000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697227]\n",
            "step = 843000, loss = 5.857442378997803, weight = [1.1919975], bias = [-33.69721]\n",
            "step = 844000, loss = 5.857441425323486, weight = [1.1919955], bias = [-33.6972]\n",
            "step = 845000, loss = 5.857439041137695, weight = [1.1920024], bias = [-33.6972]\n",
            "step = 846000, loss = 5.85744047164917, weight = [1.1919924], bias = [-33.697227]\n",
            "step = 847000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 848000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.697197]\n",
            "step = 849000, loss = 5.857439041137695, weight = [1.1919969], bias = [-33.697216]\n",
            "step = 850000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 851000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.697212]\n",
            "step = 852000, loss = 5.857439041137695, weight = [1.1920006], bias = [-33.69723]\n",
            "step = 853000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697224]\n",
            "step = 854000, loss = 5.857439041137695, weight = [1.1919976], bias = [-33.69721]\n",
            "step = 855000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.6972]\n",
            "step = 856000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697193]\n",
            "step = 857000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.69722]\n",
            "step = 858000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.697212]\n",
            "step = 859000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 860000, loss = 5.857439041137695, weight = [1.1920002], bias = [-33.697224]\n",
            "step = 861000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697212]\n",
            "step = 862000, loss = 5.857439994812012, weight = [1.1919936], bias = [-33.697212]\n",
            "step = 863000, loss = 5.857439994812012, weight = [1.1919951], bias = [-33.69724]\n",
            "step = 864000, loss = 5.857441425323486, weight = [1.1919992], bias = [-33.69722]\n",
            "step = 865000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697205]\n",
            "step = 866000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.69722]\n",
            "step = 867000, loss = 5.857441425323486, weight = [1.1919954], bias = [-33.697193]\n",
            "step = 868000, loss = 5.857439994812012, weight = [1.1919969], bias = [-33.697212]\n",
            "step = 869000, loss = 5.857439994812012, weight = [1.1919969], bias = [-33.697212]\n",
            "step = 870000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 871000, loss = 5.85744047164917, weight = [1.1919936], bias = [-33.69723]\n",
            "step = 872000, loss = 5.85744047164917, weight = [1.1919988], bias = [-33.69722]\n",
            "step = 873000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.6972]\n",
            "step = 874000, loss = 5.857441425323486, weight = [1.191992], bias = [-33.69724]\n",
            "step = 875000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.69722]\n",
            "step = 876000, loss = 5.85744047164917, weight = [1.1919988], bias = [-33.69721]\n",
            "step = 877000, loss = 5.857439041137695, weight = [1.1920029], bias = [-33.697224]\n",
            "step = 878000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.697193]\n",
            "step = 879000, loss = 5.857439994812012, weight = [1.1919987], bias = [-33.69722]\n",
            "step = 880000, loss = 5.857439041137695, weight = [1.1919945], bias = [-33.697216]\n",
            "step = 881000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.6972]\n",
            "step = 882000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.69723]\n",
            "step = 883000, loss = 5.857439041137695, weight = [1.1919881], bias = [-33.69724]\n",
            "step = 884000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.6972]\n",
            "step = 885000, loss = 5.857439041137695, weight = [1.1919935], bias = [-33.69723]\n",
            "step = 886000, loss = 5.857439994812012, weight = [1.1919923], bias = [-33.697224]\n",
            "step = 887000, loss = 5.85744047164917, weight = [1.1919875], bias = [-33.697227]\n",
            "step = 888000, loss = 5.857441425323486, weight = [1.1919965], bias = [-33.697224]\n",
            "step = 889000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697193]\n",
            "step = 890000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.69722]\n",
            "step = 891000, loss = 5.85744047164917, weight = [1.1919917], bias = [-33.69722]\n",
            "step = 892000, loss = 5.857441425323486, weight = [1.191993], bias = [-33.697227]\n",
            "step = 893000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697227]\n",
            "step = 894000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.697227]\n",
            "step = 895000, loss = 5.85744047164917, weight = [1.191995], bias = [-33.69721]\n",
            "step = 896000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697212]\n",
            "step = 897000, loss = 5.85744047164917, weight = [1.1919932], bias = [-33.697212]\n",
            "step = 898000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697216]\n",
            "step = 899000, loss = 5.857439041137695, weight = [1.1920009], bias = [-33.697224]\n",
            "step = 900000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.697205]\n",
            "step = 901000, loss = 5.857439041137695, weight = [1.1919944], bias = [-33.69722]\n",
            "step = 902000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.69721]\n",
            "step = 903000, loss = 5.85744047164917, weight = [1.1919984], bias = [-33.69722]\n",
            "step = 904000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.697224]\n",
            "step = 905000, loss = 5.857439041137695, weight = [1.1919998], bias = [-33.697227]\n",
            "step = 906000, loss = 5.8574419021606445, weight = [1.191993], bias = [-33.69723]\n",
            "step = 907000, loss = 5.85744047164917, weight = [1.1920013], bias = [-33.697212]\n",
            "step = 908000, loss = 5.85744047164917, weight = [1.1919967], bias = [-33.6972]\n",
            "step = 909000, loss = 5.857439994812012, weight = [1.1919982], bias = [-33.697212]\n",
            "step = 910000, loss = 5.857439994812012, weight = [1.1919984], bias = [-33.697224]\n",
            "step = 911000, loss = 5.857441425323486, weight = [1.1920029], bias = [-33.69722]\n",
            "step = 912000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697197]\n",
            "step = 913000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.69721]\n",
            "step = 914000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697216]\n",
            "step = 915000, loss = 5.857441425323486, weight = [1.191993], bias = [-33.697216]\n",
            "step = 916000, loss = 5.85744047164917, weight = [1.1919986], bias = [-33.697224]\n",
            "step = 917000, loss = 5.857439994812012, weight = [1.1919951], bias = [-33.697227]\n",
            "step = 918000, loss = 5.857439994812012, weight = [1.1919973], bias = [-33.69721]\n",
            "step = 919000, loss = 5.857439994812012, weight = [1.1919954], bias = [-33.6972]\n",
            "step = 920000, loss = 5.857439994812012, weight = [1.1920011], bias = [-33.6972]\n",
            "step = 921000, loss = 5.857439041137695, weight = [1.1919931], bias = [-33.697227]\n",
            "step = 922000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 923000, loss = 5.857439041137695, weight = [1.1919959], bias = [-33.697197]\n",
            "step = 924000, loss = 5.857439041137695, weight = [1.1919956], bias = [-33.697216]\n",
            "step = 925000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697216]\n",
            "step = 926000, loss = 5.857439994812012, weight = [1.1919936], bias = [-33.697212]\n",
            "step = 927000, loss = 5.857439994812012, weight = [1.191999], bias = [-33.697235]\n",
            "step = 928000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697224]\n",
            "step = 929000, loss = 5.85744047164917, weight = [1.1919974], bias = [-33.69721]\n",
            "step = 930000, loss = 5.857439994812012, weight = [1.1919953], bias = [-33.6972]\n",
            "step = 931000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697193]\n",
            "step = 932000, loss = 5.857439041137695, weight = [1.1919944], bias = [-33.69722]\n",
            "step = 933000, loss = 5.85744047164917, weight = [1.191996], bias = [-33.697212]\n",
            "step = 934000, loss = 5.857439994812012, weight = [1.1919961], bias = [-33.697197]\n",
            "step = 935000, loss = 5.857439041137695, weight = [1.1920011], bias = [-33.69722]\n",
            "step = 936000, loss = 5.85744047164917, weight = [1.1919953], bias = [-33.697212]\n",
            "step = 937000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.697212]\n",
            "step = 938000, loss = 5.85744047164917, weight = [1.1919957], bias = [-33.69724]\n",
            "step = 939000, loss = 5.857439994812012, weight = [1.1919985], bias = [-33.69722]\n",
            "step = 940000, loss = 5.857441425323486, weight = [1.1919953], bias = [-33.697205]\n",
            "step = 941000, loss = 5.85744047164917, weight = [1.1919938], bias = [-33.697224]\n",
            "step = 942000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697193]\n",
            "step = 943000, loss = 5.85744047164917, weight = [1.1919943], bias = [-33.697216]\n",
            "step = 944000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 945000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697197]\n",
            "step = 946000, loss = 5.857439994812012, weight = [1.1919938], bias = [-33.69723]\n",
            "step = 947000, loss = 5.857439041137695, weight = [1.191997], bias = [-33.697224]\n",
            "step = 948000, loss = 5.857439994812012, weight = [1.1919962], bias = [-33.6972]\n",
            "step = 949000, loss = 5.85744047164917, weight = [1.1919924], bias = [-33.69724]\n",
            "step = 950000, loss = 5.85744047164917, weight = [1.1919973], bias = [-33.69722]\n",
            "step = 951000, loss = 5.85744047164917, weight = [1.1919981], bias = [-33.697212]\n",
            "step = 952000, loss = 5.85744047164917, weight = [1.1919993], bias = [-33.697224]\n",
            "step = 953000, loss = 5.85744047164917, weight = [1.1919955], bias = [-33.697193]\n",
            "step = 954000, loss = 5.85744047164917, weight = [1.1919973], bias = [-33.69722]\n",
            "step = 955000, loss = 5.857439994812012, weight = [1.1919926], bias = [-33.69722]\n",
            "step = 956000, loss = 5.857441425323486, weight = [1.1919949], bias = [-33.69721]\n",
            "step = 957000, loss = 5.857439994812012, weight = [1.1919944], bias = [-33.69723]\n",
            "step = 958000, loss = 5.8574419021606445, weight = [1.1919917], bias = [-33.69724]\n",
            "step = 959000, loss = 5.857439994812012, weight = [1.1919966], bias = [-33.6972]\n",
            "step = 960000, loss = 5.857439994812012, weight = [1.1919935], bias = [-33.697224]\n",
            "step = 961000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.69722]\n",
            "step = 962000, loss = 5.857439994812012, weight = [1.1919913], bias = [-33.697227]\n",
            "step = 963000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.697224]\n",
            "step = 964000, loss = 5.857439994812012, weight = [1.1919957], bias = [-33.697193]\n",
            "step = 965000, loss = 5.85744047164917, weight = [1.1919951], bias = [-33.69722]\n",
            "step = 966000, loss = 5.85744047164917, weight = [1.1919934], bias = [-33.697216]\n",
            "step = 967000, loss = 5.85744047164917, weight = [1.1920013], bias = [-33.69722]\n",
            "step = 968000, loss = 5.857439041137695, weight = [1.1919967], bias = [-33.697227]\n",
            "step = 969000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.697227]\n",
            "step = 970000, loss = 5.85744047164917, weight = [1.1919974], bias = [-33.69721]\n",
            "step = 971000, loss = 5.857441425323486, weight = [1.1919966], bias = [-33.697212]\n",
            "step = 972000, loss = 5.857441425323486, weight = [1.191994], bias = [-33.69721]\n",
            "step = 973000, loss = 5.85744047164917, weight = [1.1919963], bias = [-33.697216]\n",
            "step = 974000, loss = 5.857439041137695, weight = [1.1920009], bias = [-33.697224]\n",
            "step = 975000, loss = 5.857439994812012, weight = [1.1919976], bias = [-33.697205]\n",
            "step = 976000, loss = 5.85744047164917, weight = [1.19199], bias = [-33.697224]\n",
            "step = 977000, loss = 5.85744047164917, weight = [1.1919961], bias = [-33.69721]\n",
            "step = 978000, loss = 5.857439994812012, weight = [1.1919974], bias = [-33.69722]\n",
            "step = 979000, loss = 5.85744047164917, weight = [1.1919986], bias = [-33.69722]\n",
            "step = 980000, loss = 5.857439994812012, weight = [1.1919985], bias = [-33.697227]\n",
            "step = 981000, loss = 5.857441425323486, weight = [1.1920016], bias = [-33.697224]\n",
            "step = 982000, loss = 5.857439041137695, weight = [1.1920002], bias = [-33.697212]\n",
            "step = 983000, loss = 5.857439041137695, weight = [1.1919965], bias = [-33.6972]\n",
            "step = 984000, loss = 5.857439994812012, weight = [1.1919968], bias = [-33.697212]\n",
            "step = 985000, loss = 5.857439994812012, weight = [1.191998], bias = [-33.697224]\n",
            "step = 986000, loss = 5.857441425323486, weight = [1.1920089], bias = [-33.697212]\n",
            "step = 987000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 988000, loss = 5.85744047164917, weight = [1.1919962], bias = [-33.69721]\n",
            "step = 989000, loss = 5.857439994812012, weight = [1.1919965], bias = [-33.697216]\n",
            "step = 990000, loss = 5.857439994812012, weight = [1.1919937], bias = [-33.697212]\n",
            "step = 991000, loss = 5.857443332672119, weight = [1.1919975], bias = [-33.697224]\n",
            "step = 992000, loss = 5.857439994812012, weight = [1.1919959], bias = [-33.697224]\n",
            "step = 993000, loss = 5.85744047164917, weight = [1.1919974], bias = [-33.69721]\n",
            "step = 994000, loss = 5.857439994812012, weight = [1.1919956], bias = [-33.6972]\n",
            "step = 995000, loss = 5.8574419021606445, weight = [1.1919993], bias = [-33.6972]\n",
            "step = 996000, loss = 5.857439041137695, weight = [1.1919934], bias = [-33.697224]\n",
            "step = 997000, loss = 5.857439994812012, weight = [1.1919963], bias = [-33.697212]\n",
            "step = 998000, loss = 5.857439994812012, weight = [1.191996], bias = [-33.697197]\n",
            "step = 999000, loss = 5.85744047164917, weight = [1.1919954], bias = [-33.697224]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yLbvl1endvkU"
      }
    }
  ]
}